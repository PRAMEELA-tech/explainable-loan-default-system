{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import full_preprocessing_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/home_credit/application_train_working.csv\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 105)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_percent = df.isnull().mean()\n",
    "missing_percent.sort_values(ascending=False).head(10)\n",
    "cols_to_drop = missing_percent[missing_percent > 0.65].index\n",
    "len(cols_to_drop)\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "df[cat_cols] = df[cat_cols].fillna(\"Unknown\")\n",
    "df.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "      <td>307511.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>11.909245</td>\n",
       "      <td>13.070108</td>\n",
       "      <td>10.067677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488906</td>\n",
       "      <td>0.715193</td>\n",
       "      <td>0.545872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.152338</td>\n",
       "      <td>10.714440</td>\n",
       "      <td>7.388019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.630717</td>\n",
       "      <td>12.506181</td>\n",
       "      <td>9.712630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>11.899215</td>\n",
       "      <td>13.149068</td>\n",
       "      <td>10.122784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.218500</td>\n",
       "      <td>13.603123</td>\n",
       "      <td>10.451522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.577685</td>\n",
       "      <td>15.214228</td>\n",
       "      <td>12.460818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AMT_INCOME_TOTAL     AMT_CREDIT    AMT_ANNUITY\n",
       "count     307511.000000  307511.000000  307511.000000\n",
       "mean          11.909245      13.070108      10.067677\n",
       "std            0.488906       0.715193       0.545872\n",
       "min           10.152338      10.714440       7.388019\n",
       "25%           11.630717      12.506181       9.712630\n",
       "50%           11.899215      13.149068      10.122784\n",
       "75%           12.218500      13.603123      10.451522\n",
       "max           18.577685      15.214228      12.460818"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_cols = [\n",
    "    \"AMT_INCOME_TOTAL\",\n",
    "    \"AMT_CREDIT\",\n",
    "    \"AMT_ANNUITY\"\n",
    "]\n",
    "\n",
    "for col in financial_cols:\n",
    "    df[col] = np.log1p(df[col])\n",
    "df[financial_cols].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84754/1082058328.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"CREDIT_TO_INCOME\"] = df[\"AMT_CREDIT\"] / df[\"AMT_INCOME_TOTAL\"]\n"
     ]
    }
   ],
   "source": [
    "df[\"CREDIT_TO_INCOME\"] = df[\"AMT_CREDIT\"] / df[\"AMT_INCOME_TOTAL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84754/2616395262.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ANNUITY_TO_INCOME\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_INCOME_TOTAL\"]\n"
     ]
    }
   ],
   "source": [
    "df[\"ANNUITY_TO_INCOME\"] = df[\"AMT_ANNUITY\"] / df[\"AMT_INCOME_TOTAL\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84754/204255143.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"AGE_YEARS\"] = df[\"DAYS_BIRTH\"] / -365\n"
     ]
    }
   ],
   "source": [
    "df[\"AGE_YEARS\"] = df[\"DAYS_BIRTH\"] / -365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84754/1626473903.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"EMPLOYMENT_YEARS\"] = df[\"DAYS_EMPLOYED\"] / -365\n"
     ]
    }
   ],
   "source": [
    "df[\"EMPLOYMENT_YEARS\"] = df[\"DAYS_EMPLOYED\"] / -365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREDIT_TO_INCOME</th>\n",
       "      <th>ANNUITY_TO_INCOME</th>\n",
       "      <th>AGE_YEARS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.057051</td>\n",
       "      <td>0.827812</td>\n",
       "      <td>25.920548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.125273</td>\n",
       "      <td>0.838217</td>\n",
       "      <td>45.931507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062333</td>\n",
       "      <td>0.792943</td>\n",
       "      <td>52.180822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.071100</td>\n",
       "      <td>0.871789</td>\n",
       "      <td>52.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.123027</td>\n",
       "      <td>0.853518</td>\n",
       "      <td>54.608219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CREDIT_TO_INCOME  ANNUITY_TO_INCOME  AGE_YEARS\n",
       "0          1.057051           0.827812  25.920548\n",
       "1          1.125273           0.838217  45.931507\n",
       "2          1.062333           0.792943  52.180822\n",
       "3          1.071100           0.871789  52.068493\n",
       "4          1.123027           0.853518  54.608219"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"CREDIT_TO_INCOME\", \"ANNUITY_TO_INCOME\", \"AGE_YEARS\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 220)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 219), (307511,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(\"TARGET\", axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 219 feature names.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "joblib.dump(feature_names, \"../models/feature_names.pkl\")\n",
    "\n",
    "print(\"Saved\", len(feature_names), \"feature names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 219)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/home_credit/X_clean.npy\", X_scaled)\n",
    "np.save(\"../data/home_credit/y_clean.npy\", y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/standard_scaler.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"../models/standard_scaler.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StandardScaler', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'encode_features', 'engineer_features', 'full_preprocessing_pipeline', 'impute_missing', 'joblib', 'log_transform', 'np', 'os', 'pd', 'remove_high_missing', 'scale_features']\n"
     ]
    }
   ],
   "source": [
    "import src.data_preprocessing as dp\n",
    "\n",
    "print(dir(dp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_splitting.py created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create data_splitting.py inside src folder\n",
    "\n",
    "file_path = \"../src/data_splitting.py\"\n",
    "\n",
    "code = \"\"\"\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def stratified_split(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=test_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def apply_smote(X_train, y_train, random_state=42):\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled\n",
    "\"\"\"\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(code)\n",
    "\n",
    "print(\"data_splitting.py created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from imbalanced-learn) (1.8.0)\n",
      "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from imbalanced-learn) (0.1.5)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from imbalanced-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from imbalanced-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m26.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_splitting import stratified_split, apply_smote\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (307511, 219)\n",
      "y shape: (307511,)\n"
     ]
    }
   ],
   "source": [
    "X_scaled, y = full_preprocessing_pipeline(\n",
    "    \"../data/home_credit/application_train_working.csv\"\n",
    ")\n",
    "\n",
    "print(\"X shape:\", X_scaled.shape)\n",
    "print(\"y shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_splitting import stratified_split, apply_smote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (246008, 219)\n",
      "Test shape: (61503, 219)\n",
      "\n",
      "Train distribution:\n",
      "[226148  19860]\n",
      "\n",
      "Test distribution:\n",
      "[56538  4965]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = stratified_split(X_scaled, y)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "\n",
    "print(\"\\nTrain distribution:\")\n",
    "print(np.bincount(y_train))\n",
    "\n",
    "print(\"\\nTest distribution:\")\n",
    "print(np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE distribution:\n",
      "[226148 226148]\n",
      "Balanced train shape: (452296, 219)\n"
     ]
    }
   ],
   "source": [
    "X_train_bal, y_train_bal = apply_smote(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTE distribution:\")\n",
    "print(np.bincount(y_train_bal))\n",
    "\n",
    "print(\"Balanced train shape:\", X_train_bal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
